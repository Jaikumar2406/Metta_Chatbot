# ğŸ§  MeTTa RAG Application

## ğŸ“˜ Overview
This project is a **RAG (Retrieval-Augmented Generation)** application built using **MeTTa documents** as the knowledge base.  
It allows users to **ask any question related to MeTTa**, and the system provides **code-only answers** in the MeTTa language.

---

## âš™ï¸ How It Works
- Collected and processed all official **MeTTa documentation**  
- Used those documents as the **retrieval source** for a RAG pipeline  
- Integrated a **language model** that understands MeTTa syntax and semantics  
- When a user asks a question, the app:
  - Retrieves the most relevant MeTTa docs  
  - Generates a **code-only answer** without any explanation â€” just pure MeTTa code

---

## ğŸ’¡ Example

**Question:**
```text
How to define a simple function in MeTTa?
```

**Answer:**
```text
(= (square $x) (* $x $x))
```
## ğŸ§© Features

ğŸ§  RAG-based contextual MeTTa retrieval

ğŸ’¬ Understands MeTTa syntax and semantics

ğŸ’» Code-only responses (no explanations)

ğŸŒ Full-stack setup (Backend + Frontend)

âš¡ Fast, accurate, and interactive user interface

ğŸ” Efficient document search and retrieval pipeline

ğŸ§± Easily extensible for new datasets or knowledge bases

## ğŸ§° Tech Stack

- Backend: Python, FastAPI, LangChain / RAG pipeline
- Frontend: React + Tailwind CSS
- Database: Pinecone 

## ğŸ§‘â€ğŸ’» Installation
ğŸ”¹ Clone the Repository
git clone https://github.com/Jaikumar2406/Metta_Chatbot.git
cd Metta_Chatbot

ğŸ”¹ Backend Setup
pip install -r requirements.txt
uvicorn main:app --reload

The backend will start running on
ğŸ‘‰ http://127.0.0.1:8000

ğŸ”¹ Frontend Setup
cd client
npm install
npm start

The frontend will start at
ğŸ‘‰ http://localhost:3000

**ğŸ’¬ â€œAsk questions. Get pure MeTTa code.â€**
